# 第八周总结

李老师，我这周的主要工作是在搞代码，近段时间也都是在代码花的时间比较多，论文反而没怎么看，笔记就还没更新。这段时间在代码上有了不少提升**，课题的方向基本上确定**。

本周主要：

+ 我对比了Cifar数据集在 ResNet 和 WideResNet 的结果，对比了两个网络的差别

+ 那篇文章有提供的**所有的代码我都调试出来了**

  昨天作者又更新了多分类的OOD代码，还有之前一份对抗训练的代码也做了更新，之前报错一直卡住的地方，现在也解决了，**平台搭建完成**，我以后的工作主要围绕着这个来做。

![1587721145383](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587721145383.png)



对抗训练真的是特别慢，单单跑cifar10这个数据集，用了ACM两张卡48G显存，如此高配置下都整整跑了两天

![1587721635249](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587721635249.png)

好在跑出来了结果很好，文中报告的是83.5%，相差无几，这是clean状况下的结果，还没有加入PGD攻击，具体的PDG是怎么攻击的，暂时还不明白

![1587721823199](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587721823199.png)

从结果来看，这里有一个有趣的现象，在clean情况下的对抗训练，效果要比不加self-supervised惩罚的效果要稍微好一点（也不是特别明显），但是当样本被攻击了以后，加了self-supervised的惩罚这种好处体现就比较明显了。上边结果中攻击20 step和攻击了100 step以后结果是一样的，是因为攻击了20次这种，就已经达到了bound，PGD是一种投影的方法，后边的攻击就被投影到bound之内，不会再起作用。

![1587721302417](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587721302417.png)

其他的实验也都能跑出来，从所有实验复现出来的结果看，和论文中的误差不超过5%，还是蛮准的

![1587724619395](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587724619395.png)

目前还有两个份代码没有开源出来，如上

+ CIFAR-10-C的意思是，CIFAR10的数据被污染了，C代表的是Corruption
+ OOD-CIFAR 这个意思是CIFAR数据集的OOD代码

作者后续或许还会上传代码，不上传也没关系，根据现有的资源应该能够写出来。

其中CIFAR-10-C这一部分，在之前的工作，又有提供完整的代码，只是没有加入自监督的罚项；而另外一个CIFAR的OOD代码更容易一些，因为他有提供了imagenet子集数据集的实现，在此基础上应该能做出来

到此，我的工作平台算是基本上搭起来了，作者代码写得很漂亮，看他的代码也能学到很多东西。运气比较好，找到这么好的资源，还好老师在我快要放弃它的时候让我坚持下来了:=



这篇文章，刚开始看起来的时候真的是非常让我头疼，内容是在是太多了，是对之前所有工作的一个拓展，在短小的体量之下其实蕴涵了大量丰富的内容，所以最开始真的是让我感觉非常的吃力。

文章看似内容很多，其实基本上都是围绕在一件事情干，更确切的可以说是弱监督这个框架之下的问题，也就是老师说的，之所有写在一起肯定是有很多的共通性的，我现在慢慢开始体会到这种思路了。  

**接下来我的工作还是很明确**，就是围绕着这篇文章做，结合作者之前的工作，比较典型的比如outlier-exposure和glc，把具体的细节搞清楚，代码搞清楚，抓准主线，在这个过程当中，肯定是能够找到和发现问题的。



关于弱监督：其实标签污染这一块，这是当前研究的重点，也是由于人工标注的费时费力，而且不准确，这个和自监督的出发点如出一辙（或者说就是一个东西）有个研究弱监督的方法是label-noise learning，这个是现在研究的重点，基本思路是这样：

> 有少量的样本的标签是真是可信的，大量的标签是带noise的；用真实标签去学习一个真实的后验概率，然后基于一些假设去学习下面这个红框的条件分布，有了这两部分以后，带noise的分类器就可以算出来了。

现在大量的工作都是去找这个矩阵怎么求，目前有很多工作基于不同的假设提出不一样的方法。

![1587727815010](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587727815010.png)





## 简单总结一下self-supervised

 CS231n课程当中，对正则化做了一个比较general的定义，我们平时说的正则化在就是加一个罚项，正则化的主要作用是防止过拟合：主要有

+ Add a regular term
+ Data Augmentation
+ Dropout
+ Early Stop

关于自监督学习，是因何提出的，目的是要解决的是一个什么问题，这种基本问题现在大致清楚了。自监督简单来说，就是不需要再人为进行数据标注，用数据本身的属性，作为监督信号（替代监督学习中需要人为标注的信号），然后用监督学习的方法去正常的训练一个网络，最后再来一个迁移学习的步骤。它的这个角度相对于其他的方法来说确实是很fancy。

我自己理解的自监督也是一种数据增强的方法，文中作为一个罚项加到Loss中去，"似乎"很自然。但是具体为什么可以做到这种效果，还要仔细琢磨。



我觉得非常典型，能够说明问题的工作有两个：

1. 第一个就是把图片先变成灰度图，用原始图像作为这个灰度图的标签去学习一个分布

    https://arxiv.org/abs/1603.08511 

![1587723500746](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587723500746.png)

效果非常的直观，效果蛮好的，这里用到了生成模型

![1587723688503](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587723688503.png)

2. 另一个用的最多，也是很典型的就是我最开始的看看的预测图像旋转的角度这一个

    https://arxiv.org/abs/1803.07728 

   这个的思路也很简单很直观，建模成一个分类的问题，用的是Cross Entropy作为损失函数。还有其他很多的代理任务，也都是建模成做简单的分类问题来处理

   ![1587723912690](C:\Users\Church\AppData\Roaming\Typora\typora-user-images\1587723912690.png)

